# Quick Reference: Paper Sources & Project Selection Summary

## QUICK ACCESS: TOP 50 PAPERS WITH DIRECT LINKS

### Must-Read Papers (10 papers to start)
1. AlexNet (2012) - https://www.cs.toronto.edu/~fritz/absps/imagenet.pdf
2. ResNet (2015) - https://arxiv.org/abs/1512.03385
3. Vision Transformer (2020) - https://arxiv.org/abs/2010.11929
4. Swin Transformer (2021) - https://arxiv.org/abs/2105.01601
5. YOLO (2015) - https://arxiv.org/abs/1506.02640
6. Faster R-CNN (2015) - https://papers.nips.cc/paper/5638-faster-r-cnn-towards-real-time-object-detection-with-region-proposal-networks
7. DETR (2020) - https://arxiv.org/abs/2005.12872
8. U-Net (2015) - https://arxiv.org/abs/1505.04597
9. DeepLab (2016) - https://arxiv.org/abs/1606.00915
10. FaceNet (2015) - https://arxiv.org/abs/1503.03832

### All 50+ Papers Quick Reference

**Classification & Architectures**
- AlexNet (2012): 35,000 citations
- VGGNet (2014): 152,000 citations
- ResNet (2015): 291,669 citations
- Inception (2015): 22,000 citations
- Vision Transformer (2020): 50,000+ citations
- Swin Transformer (2021): 37,528 citations
- SENet (2017): 45,765 citations

**Object Detection**
- YOLOv1 (2015): 68,323 citations - https://arxiv.org/abs/1506.02640
- YOLOv2 (2016): 26,732 citations - https://arxiv.org/abs/1612.08242
- YOLOv3 (2018): 37,441 citations - https://arxiv.org/abs/1804.02767
- Faster R-CNN (2015): 56,588 citations - NIPS paper
- FPN (2016): 35,800 citations - https://arxiv.org/abs/1612.03144
- DETR (2020): 21,049 citations - https://arxiv.org/abs/2005.12872

**Segmentation**
- DeepLab (2016): 25,758 citations - https://arxiv.org/abs/1606.00915
- DeepLabv3+ (2018): 22,008 citations - https://arxiv.org/abs/1802.02611
- U-Net (2015): 122,795 citations - https://arxiv.org/abs/1505.04597
- Mask R-CNN (2017): 46,121 citations - https://arxiv.org/abs/1703.06870
- Panoptic Segmentation (2019): 2,204+ citations - https://arxiv.org/abs/1801.00868
- OSVOS (2017): 1,212 citations - https://arxiv.org/abs/1611.05198

**Face Recognition**
- FaceNet (2015): 19,962 citations - https://arxiv.org/abs/1503.03832
- ArcFace (2018): 10,000+ citations - https://arxiv.org/abs/1801.07698

**3D Vision**
- PointNet (2016): 21,958 citations - https://arxiv.org/abs/1612.00593
- PointNet++ (2017): 16,302 citations - https://arxiv.org/abs/1706.02413
- Point-GNN (2020): 1,199 citations - https://arxiv.org/abs/2003.01251

**Self-Supervised Learning**
- BYOL (2020): 9,355 citations - https://arxiv.org/abs/2006.07733
- DINOv3 (2024): State-of-the-art SSL - arXiv:2508.10104
- Vision-Language Survey (2025): https://arxiv.org/abs/2501.02189

**Video & Temporal**
- TAda (2021): 80 citations - https://arxiv.org/abs/2110.06178
- MeViS (2023): 196 citations - https://arxiv.org/abs/2308.08544
- Video Anomaly Detection Survey (2024): 34 citations - https://arxiv.org/abs/2409.05383

**Pose Estimation**
- HRNet (2019): 6,827 citations - https://arxiv.org/abs/1902.09212
- HigherHRNet (2020): 1,100 citations - https://arxiv.org/abs/1908.10357

**Attention Mechanisms**
- SENet (2017): 45,765 citations - https://arxiv.org/abs/1709.01507
- scSE Networks (2018): MICCAI paper - arXiv:1803.02579

**Generative Models**
- GAN (2014): 90,000 citations - https://arxiv.org/abs/1406.2661
- Diffusion+GAN (2022): 368 citations - https://arxiv.org/abs/2206.02262

---

## FINAL PROJECT SELECTION DECISION TREE

```
START: "Which project interests you most?"

â”œâ”€ "I want to extend my food work" 
â”‚  â””â”€â†’ TRACK A: Few-Shot Food Classification â­ BEST
â”‚      (24 months, high impact, natural progression)
â”‚
â”œâ”€ "I'm passionate about food waste sustainability"
â”‚  â””â”€â†’ TRACK B: Anomaly Detection for Waste â­ RECOMMENDED
â”‚      (22 months, highest practical impact, ML engineer value)
â”‚
â”œâ”€ "I want to work with cutting-edge generative AI"
â”‚  â””â”€â†’ TRACK C: Vision-Language Models
â”‚      (24 months, needs significant GPU, highest research value)
â”‚
â”œâ”€ "I care about deployment and efficiency"
â”‚  â””â”€â†’ TRACK D: Efficient Segmentation
â”‚      (22 months, practical, mobile deployment)
â”‚
â””â”€ "I want high-impact domain (medical/safety-critical)"
   â””â”€â†’ TRACK E: Medical Imaging
       (24 months, high responsibility, interpretability focus)
```

---

## YOUR PERSONALIZED RECOMMENDATION

### Based on Your Profile:
- **Background**: Recent CS AI graduate, Master's in Data Science & AI
- **Interests**: Computer Vision, Generative AI, Portfolio building
- **Experience**: PyTorch, TensorFlow, Indian Foodvision project
- **Goal**: Remote ML engineer/data scientist role in India

### TOP CHOICE: **TRACK A - Few-Shot Learning for Food Classification**

**Why This Is Your Best Path**:
1. Natural extension of your Indian Foodvision project
2. Builds specific expertise in food domain
3. 24-month research depth is realistic
4. Strong portfolio story: "Extended food vision from 5 to 500+ food types with few-shot learning"
5. Publication-worthy novelty (few-shot + food domain combo)
6. Practical business application (restaurant chains can use this)
7. Clear benchmarks and evaluation metrics
8. LinkedIn content goldmine (50+ posts over 24 months)

**How to Position for Jobs**:
- LinkedIn: "Building few-shot learning systems for food recognition - extending my Indian Foodvision project to identify new dishes with just 5-10 examples"
- Resume: "Developed novel few-shot learning approach achieving 85% accuracy on novel food categories with <10 examples per class"
- Portfolio: Deployed model recognizing 500+ Indian food varieties
- GitHub: 5K+ stars for reproducible research code

### BACKUP CHOICE: **TRACK B - Real-Time Anomaly Detection for Food Waste**

**Why This Is Your Backup**:
1. Directly addresses your stated smart food-waste detection interest
2. Higher practical business impact (actual revenue potential)
3. Slightly easier publication (less competitive domain)
4. Strong sustainability narrative for ESG-focused companies
5. Can be deployed with lower computational resources
6. Real-world problem: Estimated $1.3T food waste annually

**How to Position for Jobs**:
- "Built real-time food waste detection system achieving 95% recall with <50ms latency on edge devices"
- Focus: ML engineer role + sustainability angle
- Companies: Food delivery apps, restaurants, supermarkets, waste management

---

## 30-SECOND PROJECT PITCH TEMPLATE

### For Track A: Few-Shot Learning
"I'm extending my Indian Foodvision project by implementing novel few-shot learning techniques. The goal is to enable food recognition systems to identify new dishes with just 5-10 examples, without retraining on the entire dataset. This has applications in restaurant discovery apps, dietary recommendation systems, and food waste reduction. Current baseline achieves 80% accuracy on novel food categories; targeting 90%+ with domain adaptation."

### For Track B: Anomaly Detection
"I'm building a real-time food waste detection system for restaurants and cafeterias. Using temporal anomaly detection with efficient neural networks, the system can identify improper food storage or waste patterns at <50ms latency on edge devices like Raspberry Pi. This enables automated alerts and behavioral nudges to reduce food waste. Potential impact: 10-20% waste reduction per establishment."

---

## FIRST MONTH ACTION PLAN

### Week 1: Setup & Planning
- [ ] Create GitHub repository: `food-few-shot-learning` (or `food-waste-detection`)
- [ ] Set up Python environment: PyTorch, CUDA, Jupyter
- [ ] Read papers: ResNet â†’ Vision Transformer â†’ Few-Shot Survey (if Track A)
- [ ] Create project proposal document (500 words)
- [ ] First LinkedIn post: "Starting 2-year computer vision research project..."

### Week 2-3: Baseline Setup
- [ ] Download Food-101 or custom food dataset
- [ ] Implement baseline classifier (ResNet-50 on full dataset)
- [ ] Achieve benchmark accuracy (80%+ on standard training)
- [ ] Document hyperparameters and training procedure
- [ ] Create benchmark comparison table

### Week 4: First Novel Direction
- [ ] Read 2 domain-specific papers (few-shot or anomaly detection)
- [ ] Identify 2-3 potential improvements over baseline
- [ ] Formulate hypothesis for first experiment
- [ ] Plan Week 5 experiments
- [ ] Share progress: "Week 1-4 baseline reproduction complete, starting novel contributions..."

### Month 2: First Iteration
- [ ] Implement first novel component (should take 2-4 weeks)
- [ ] Run ablation studies
- [ ] Compare with baseline
- [ ] Document findings
- [ ] Share: "First novel approach shows X% improvement over baseline..."

---

## RESOURCE CHECKLIST

### Computing Resources (Critical)
- **GPU**: NVIDIA RTX 3090 or A6000 (if have own machine) OR Google Colab Pro ($10/month)
- **Storage**: 500GB+ SSD (datasets are large)
- **RAM**: 32GB+ recommended
- **Budget**: $0-2000 depending on setup

### Software Stack (Standardized)
- **Framework**: PyTorch (primary), PyTorch Lightning (training)
- **Visualization**: Tensorboard, Wandb (weights & biases)
- **Deployment**: ONNX, TensorRT (if efficiency track)
- **Version Control**: Git + GitHub
- **Documentation**: Jupyter Notebooks + README + Wiki

### Datasets by Track
**Track A (Few-Shot)**:
- Food-101 (101 food categories, 101K images)
- UECFOOD-256 (256 Japanese food dishes)
- Custom Indian food dataset
- ImageNet-21k (pretraining)

**Track B (Anomaly Detection)**:
- UCF-Crime (1900 surveillance videos)
- Avenue dataset (30 videos)
- Custom food waste dataset (you create)

**Track C (Vision-Language)**:
- COCO Captions (330K images + captions)
- Conceptual 12M (12M images with captions)
- Food-101 + recipe descriptions (create custom)

**Track D (Efficient Segmentation)**:
- Cityscapes (50K images, street scenes)
- ADE20K (27K images)
- COCO Panoptic (330K images)

**Track E (Medical Imaging)**:
- BraTS (brain tumor dataset)
- COVID-CT (760 CT scans)
- ISBI medical challenges

---

## PUBLICATION STRATEGY TIMELINE

### Track A: Few-Shot Learning
- **Month 3**: ArXiv preprint (v1) - "Baseline reproduction + initial experiments"
- **Month 8**: ArXiv preprint (v2) - "Complete novel contribution"
- **Month 12**: Submit to CVPR workshops or IJCAI
- **Month 18-20**: Major revision + submit to CVPR/ICCV
- **Month 24**: Published or under review at top venue

### Track B: Anomaly Detection  
- **Month 3**: ArXiv preprint (v1)
- **Month 9**: ArXiv preprint (v2) - "Complete system"
- **Month 12**: Submit to CVPR workshops or WACV
- **Month 18**: Submit to top-tier venue
- **Month 24**: Published or accepted pending minor revisions

### Conference Submission Timeline
- **CVPR**: Deadline usually March (papers 12+ months in)
- **ICCV**: Deadline usually March (alternate years)
- **ECCV**: Deadline usually March (alternate years)
- **WACV**: Deadline usually June (Papers 6-9 months in)
- **IEEE/ACM**: Various deadlines, usually accept papers 3-6 months in

---

## LINKEDIN CONTENT CALENDAR (Sample)

### Month 1-3: "Building Foundation"
- Week 1: "Starting 2-year CV research project on [topic]"
- Week 2: "Why [domain] matters for food tech"
- Week 3: "Deep dive into paper: ResNet"
- Week 4: "Setting up PyTorch training pipeline for food images"

### Month 4-6: "First Experiments"
- Week 16: "Baseline achieved: X% accuracy"
- Week 18: "Paper analysis: [Key Paper Name]"
- Week 20: "First novel approach shows +5% improvement"
- Week 24: "Comparing 5 different loss functions for [task]"

### Month 7-12: "Building Momentum"
- "Week 30: "Half-year research update: [achievements]"
- Week 35: "How domain adaptation improves food recognition"
- Week 40: "Ablation study insights from [component]"
- Week 48: "Preparing first arxiv submission..."

### Month 13-24: "Publishing & Impact"
- "ArXiv preprint released: [Link]"
- "Paper accepted to [Conference]!"
- "Demo: Real-time food recognition with [method]"
- "Deployment on mobile: [Results]"

---

## COMMON PITFALLS TO AVOID

1. **Pitfall**: Jumping to novel ideas without solid baseline
   **Fix**: Spend Month 1-2 on baseline reproducibility

2. **Pitfall**: Not tracking experiments systematically
   **Fix**: Use Weights & Biases or MLflow from day 1

3. **Pitfall**: Choosing overly ambitious research direction
   **Fix**: Start with 1 modification to baseline, scale up gradually

4. **Pitfall**: Not documenting code and findings
   **Fix**: Create weekly summary documents + commented code

5. **Pitfall**: Ignoring computational constraints
   **Fix**: Profile code early (GPU memory, inference time)

6. **Pitfall**: Not comparing fairly with baselines
   **Fix**: Same training setup, hyperparameters, random seeds

7. **Pitfall**: Waiting for perfect results before sharing
   **Fix**: Share intermediate results and failures on LinkedIn

8. **Pitfall**: Not building network during research
   **Fix**: Engage with authors, join communities, attend conferences

---

## SUCCESS METRICS FOR 2-YEAR PROJECT

### Year 1: Foundation
- âœ… 3-5 baseline methods implemented
- âœ… 1 novel component with ablation studies
- âœ… Technical report (10+ pages)
- âœ… GitHub repo with 100+ stars
- âœ… 20+ LinkedIn posts

### Year 2: Impact
- âœ… ArXiv preprint published
- âœ… Conference submission (CVPR/ICCV/WACV)
- âœ… Deployable demo/app
- âœ… 500+ GitHub stars
- âœ… 50+ LinkedIn posts
- âœ… 3-5 speaking engagements/workshops

### Career Impact
- âœ… Portfolio project impresses companies
- âœ… Technical credibility established
- âœ… Strong interview narratives
- âœ… Network of CV researchers built
- âœ… Potential publication on CV resume

---

## FINAL CHECKLIST BEFORE STARTING

- [ ] Chosen project track (A, B, C, D, or E)
- [ ] GitHub repo created and initialized
- [ ] Development environment set up and tested
- [ ] First 3 key papers downloaded and read
- [ ] Baseline dataset downloaded (test on small subset first)
- [ ] 30-second pitch written and practiced
- [ ] LinkedIn post drafted (launch on Day 1)
- [ ] Monthly goals defined for Year 1
- [ ] Accountability partner identified (for check-ins)
- [ ] Time commitment confirmed (minimum 15-20 hours/week)

**You're ready to begin your 2-year research journey! ðŸš€**

---

## APPENDIX: HOW TO READ A RESEARCH PAPER EFFICIENTLY

For your 50+ papers, use this technique (5-pass approach):

**Pass 1 (10 min): Get the gist**
- Title, abstract, figures, conclusions
- Understand problem and solution at high level

**Pass 2 (20 min): Understand approach**
- Introduction, methodology, experiments
- Take notes on key ideas and equations

**Pass 3 (30 min): Deep dive (if important)**
- Mathematical details, proofs, algorithms
- Understand why method works

**Pass 4 (1+ hour): Implementation**
- Study code if available
- Reproduce key results

**Pass 5 (Implementation): Build**
- Implement from scratch based on understanding
- This is when you truly learn

**For this project**: Do full 5-pass on 7 key papers, 2-pass on 20 supporting papers, 1-pass on remaining 23 papers.

Good luck! ðŸŽ¯
